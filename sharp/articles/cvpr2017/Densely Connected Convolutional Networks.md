# DenseNets
https://github.com/liuzhuang13/DenseNet


1. they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters.


 Stochastic Depth Networks
 Partial DenseNets


# Deep Residual Learning
https://arxiv.org/pdf/1512.03385.pdf
https://github.com/KaimingHe/deep-residual-networks

## a general tutorial
Summary	of	observations
• Keep	the	shortest	path	as	smooth	as	possible
  by	making	ℎ and	f identity
  forward/backward	signals	directly	flow	through	this	path
• Features	of	any	layers	are	additive	outcomes
• 1000-layer ResNets	can	be	easily	trained	and	have
better	accuracy

## Highway Networks
https://github.com/fomorians/highway-cnn it helps us understand how to handle the input,awesome !



<!-- 有一种迷信， 那就是只要可以更加深的网络，那么就是可以实现更加好的预测，所需要做的事情解决深的问题，网络的好处就可以有了 -->
<!-- condesed networks because it can transfer message to the information from layers directly to other layers, I am wondering ,if the connection can be leanrned during the trained, instead of just densed ! -->
