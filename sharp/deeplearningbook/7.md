# Applications
1. Applications should not be just this , but why we are limited to this area ?
## 4 Natural language Processing

### 4.1 n-grams
1. why one why to view a classical n-gram model is that it it performing neareat-neighbor lookup ?
2. why "it can be view as a local non-parametric predictior" ?

### 4.2 Neural Language Models
1. how NLM overcome the dimensionity ?
2. what is distributed representation of words ?
3. embedding

### 4.3 High-Dimensional Outputs

big vocabulary leads to huge output which makes the training and testing being highly costed in computations and ram
#### 4.3.1 Use of a Short List
limit the vocabulary size
#### 4.3.2 Hierarchical Softmax
make the output be a tree and explain why optimal binary code is not practical

#### 4.3.3 Importance Sampling
1. wocao totally confused
2. proposal distribution is ?

#### 4.3.4 Noise-Contrastive Estimation and Ranking Loss
too short to any thing

### 4.4 Combining Neural Language Models with n-grams
how to add the capacity and don't increase too many computations

### 4.5 Neural Machine Translation

#### 4.5.1 Using an Attention Mechanism and Aligning Pieces of Data
### 4.6 Historical Perspective

## 5 Other Applications
### 5.1 Recommender System
### 5.2 Exploration Versus Exploitation
