# CNN
1. why convolution can capture the feature ?
2. what is the connections bwtween the CNN and RNN ? as far as I see, maybe the vedio can be combination of them !
3. How we understand features in this context, features are pick by ourself or learn by training ? : by training
4. is there any possible way to optimize the back-propagation for CNN, allowing for CNN has specific structure ?
5. why the shape of kernels are restricted to grid-like, other shape maybe useful !
6. It seems that every convolution layer following with an pooling layer, the reasons of it, try something different ?
7. how to chooose the architecture of cnn ?
8. try to compute the back-propagation for cnn.
9. why we need an relu layer after maxpooling, instead just maxpooling with zero ?
10. where we define the output channel ?
11. downsample anything new ?
13. accoroding to the code provided by the tensorflow, bais after the conv seems unnatural, why there only a bias shaped (30, ) ,instead of (width, heights ,30)
14.

## The Convolution Operation
cross-correlation :without fliup the kernels
Discrete convolution can viewed as multiplication by a matrix
1. the difference between the mathmaticle convolution and dl convolution ?
2. give an example for high dimension kernels and computate it !
3. why the 9.5 is easy to implemented ! less variation, variation means what.
4. univariate discrete convolution can be viewed as  Toeplitz martix
5. Any neural network  that works with matrix multiplication and does not depend on specific properties of the matrix structure should work with convolutionã€‚

## Motivation
Convolution leverage three important ideas that can be help imporve a machine learning system: sparse interaction  parameter sharing and equivariant
sparse interaction(sparse connectivity or sparse weight)
parameter sharing(tied weights)
1. the benefits of sparse interaction: only some information is important, few calculations, and this allow the network to efficiently describe complicated interaction between many variable by constructing such interaction from simple building blocks that each describe only sparse interaction.
2. parameter sharing reduce the cost in cpu and ram sharply, but why it can be guarantee it will not influence the quality of neuro nwtworks
3. particular form of parameter sharing cause the layer to have a property called equivarice to translation, what is the particular ?
4. show some example of equivarice

## Pooling
an typical layer of convolution nwtwork consist of three satges: convolution  detector stage  and pooling function
A pooling function replace the output of the net as a certain location with a summary statistic of the nearby output
pooling helps to make  the representation become approximately invariant to samll translation of the input.
invariance to local translation can be a very important property when we care more about whether some feature is present than exactly where it is
1. why cnn can adapt to different input size? : accomplished by varying the size of an offset bwtween pooling regions so that the classfication layers always receive the same number of summary statistic regardless of the input size.
2. what is dectors ? :nonliear activation function such as relu
3. can we specify the dectors for the cnn
4. it is also possible to dynamically pool features together ?
5. Another approch is to learn a single pooling structure that is then applied to all images
6. how pooling move across the iamge ?
## Convolution and Pooling as Infinitely Strong Prior
1. why infinitely strong prior:  a.weight is identical  b.weights are zero

## 5 Variant of the Basic Convolution function
1. how this is different from the trandition math ? this difference lead what kinds of godness ?
2. why batch mood means 4D if the input and output is 3D ? batch is what ?
3.
4. having seen so much variants of convolution function, design one by yourself and explain the motivations of it and I am wondering can we have make a convolution kernels move with the training go on ?
5. filter
6.

## 7 Data Type
1. dimension and channel ? : My viewpoint, channel just an special dimension
2. ...only the case where every example in the train and test has the same spatial dimension
3. how we deal with different input size ?
4. different amount observation and different kinds of observations ?

## 8 Efficient Convolution Algorithm
1. in the commericial setting, it is typical to devote more resources to deployment of a network than ot its training. what it is the meaning of deployment of a network ?

## 9 Random or Unsupervised Features
1. convolution deep belif network ?
2. in layer-wise pretraining, what is the means of extract all features from the first layer ?
3.
## 11 Convolution Networks and History of Deep Learning
